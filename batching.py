import torch
import torch.nn as nn
from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights
import os

# === 1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Multi-Head –º–æ–¥–µ–ª–∏ ===
class MobileNetV3_MultiHead(nn.Module):
    def __init__(self, num_classes1=5, num_classes2=5):
        super().__init__()
        base = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT)
        self.features = base.features
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.flatten = nn.Flatten()

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—Ö–æ–¥–∞
        with torch.no_grad():
            dummy = torch.randn(1, 3, 224, 224)
            out = self.flatten(self.pool(self.features(dummy)))
            in_features = out.shape[1]

        self.head1 = nn.Linear(in_features, num_classes1)  # brand
        self.head2 = nn.Linear(in_features, num_classes2)  # color

    def forward(self, x):
        x = self.features(x)
        x = self.pool(x)
        x = self.flatten(x)
        return self.head1(x), self.head2(x)

# === 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –≤–µ—Å–æ–≤ ===
model = MobileNetV3_MultiHead()
model.load_state_dict(torch.load("multihead_best.pth", map_location="cpu"))
model.eval()

# === 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏–∫—Ç–∏–≤–Ω–æ–≥–æ –≤—Ö–æ–¥–∞ —Å batch_size > 1 ===
dummy_input = torch.randn(4, 3, 224, 224)  # Batch size 4, –º–æ–∂–Ω–æ –ª—é–±–æ–µ >1

# === 4. –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –æ—Å—å—é batch_size ===
output_path = "multihead(batching).onnx"
torch.onnx.export(
    model,
    dummy_input,
    output_path,
    input_names=["input"],
    output_names=["brand", "color"],
    opset_version=11,
    dynamic_axes={
        "input": {0: "batch_size"},
        "brand": {0: "batch_size"},
        "color": {0: "batch_size"}
    }
)

print(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω: {output_path}")
print(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {round(os.path.getsize(output_path) / 1024 / 1024, 2)} MB")
